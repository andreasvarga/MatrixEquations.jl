var documenterSearchIndex = {"docs":
[{"location":"meutil.html#Matrix-Equations-Utilities-1","page":"Matrix Equations Utilities","title":"Matrix Equations Utilities","text":"","category":"section"},{"location":"meutil.html#","page":"Matrix Equations Utilities","title":"Matrix Equations Utilities","text":"utqu\nutqu!\nqrupdate!\nrqupdate!\nisschur\ntriu2vec\nvec2triu","category":"page"},{"location":"meutil.html#MatrixEquations.utqu","page":"Matrix Equations Utilities","title":"MatrixEquations.utqu","text":"X = utqu(Q,U)\n\nCompute efficiently the symmetric/hermitian product X = U'QU, where Q is a symmetric/hermitian matrix.\n\n\n\n\n\n","category":"function"},{"location":"meutil.html#MatrixEquations.utqu!","page":"Matrix Equations Utilities","title":"MatrixEquations.utqu!","text":"utqu!(Q,U) -> Q\n\nCompute efficiently the symmetric/hermitian product U'QU -> Q, where Q is a symmetric/hermitian matrix and U is a square matrix. The resulting product overwrites Q.\n\n\n\n\n\n","category":"function"},{"location":"meutil.html#MatrixEquations.qrupdate!","page":"Matrix Equations Utilities","title":"MatrixEquations.qrupdate!","text":"qrupdate!(R, Y) -> R\n\nUpdate the upper triangular factor R by the upper triangular factor of the QR factorization  of [ R; Y' ], where Y is a low-rank matrix Y (typically with one or two columns). The computation of R only uses O(n^2) operations (n is the size of R). The input matrix R is updated in place and the matrix Y is destroyed during the computation.\n\n\n\n\n\n","category":"function"},{"location":"meutil.html#MatrixEquations.rqupdate!","page":"Matrix Equations Utilities","title":"MatrixEquations.rqupdate!","text":"rqupdate!(R, Y) -> R\n\nUpdate the upper triangular factor R by the upper triangular factor of the RQ factorization  of [ Y R], where Y is a low-rank matrix Y (typically with one or two columns). The computation of R only uses O(n^2) operations (n is the size of R). The input matrix R is updated in place and the matrix Y is destroyed during the computation.\n\n\n\n\n\n","category":"function"},{"location":"meutil.html#MatrixEquations.isschur","page":"Matrix Equations Utilities","title":"MatrixEquations.isschur","text":" isschur(A::AbstractMatrix) -> Bool\n\nTest whether A is a square matrix in a real or complex Schur form. In the real case, it is only tested whether A is a quasi upper triangular matrix, which may have 2x2 diagonal blocks, which however must not correspond to complex conjugate eigenvalues. In the complex case, it is tested if A is upper triangular.\n\n\n\n\n\n isschur(A::AbstractMatrix, B::AbstractMatrix) -> Bool\n\nTest whether (A,B) is a pair of square matrices in a real or complex generalized Schur form. In the real case, it is only tested whether B is upper triangular and A is a quasi upper triangular matrix, which may have 2x2 diagonal blocks, which however must not correspond to complex conjugate eigenvalues. In the complex case, it is tested if A and B are both upper triangular.\n\n\n\n\n\n","category":"function"},{"location":"meutil.html#MatrixEquations.triu2vec","page":"Matrix Equations Utilities","title":"MatrixEquations.triu2vec","text":"x = triu2vec(Q; rowwise = false, her = false)\n\nReshape the upper triangular part of the nxn array Q as a one-dimensional column  vector x with n(n+1)/2 elements. Q is assumed symmetric/hermitian if her = true. The elements of x correspond to stacking the elements of successive columns of the upper triangular part of Q, if rowwise = false, or stacking the elements of successive rows of the upper triangular part of Q, if rowwise = true.\n\n\n\n\n\n","category":"function"},{"location":"meutil.html#MatrixEquations.vec2triu","page":"Matrix Equations Utilities","title":"MatrixEquations.vec2triu","text":"Q = vec2triu(x; rowwise = false, her = false)\n\nBuild from a one-dimensional column vector x with n(n+1)/2 elements an nxn upper triangular matrix Q if her = false or an nxn symetric/hermitian  array Q if her = true. The elements of x correspond to stacking the elements of successive columns of the upper triangular part of Q, if rowwise = false, or stacking the elements of successive rows of the upper triangular part of Q, if rowwise = true.\n\n\n\n\n\n","category":"function"},{"location":"riccati.html#Riccati-Matrix-Equation-Solvers-1","page":"Riccati Matrix Equation Solvers","title":"Riccati Matrix Equation Solvers","text":"","category":"section"},{"location":"riccati.html#Standard-Riccati-Matrix-Equations-1","page":"Riccati Matrix Equation Solvers","title":"Standard Riccati Matrix Equations","text":"","category":"section"},{"location":"riccati.html#","page":"Riccati Matrix Equation Solvers","title":"Riccati Matrix Equation Solvers","text":"arec\nared","category":"page"},{"location":"riccati.html#MatrixEquations.arec","page":"Riccati Matrix Equation Solvers","title":"MatrixEquations.arec","text":"arec(A, G, Q = 0; as = false, rtol::Real = nϵ) -> (X, EVALS, Z)\n\nCompute X, the hermitian/symmetric stabilizing solution (if as = false) or  anti-stabilizing solution (if as = true) of the continuous-time algebraic Riccati equation\n\n A'X + XA - XGX + Q = 0,\n\nwhere G and Q are hermitian/symmetric matrices or uniform scaling operators.  Scalar-valued G and Q are interpreted as appropriately sized uniform scaling operators G*I and Q*I.\n\nBy default, the lower bound for the 1-norm reciprocal condition number rtol is n*ϵ, where n is the order of A  and ϵ is the machine epsilon of the element type of A. \n\nEVALS is a vector containing the (stable or anti-stable) eigenvalues of A-GX.  Z = [ U; V ] is an orthogonal basis for the stable/anti-stable deflating subspace such that X = V/U. \n\nReference: Laub, A.J., A Schur Method for Solving Algebraic Riccati equations. IEEE Trans. Auto. Contr., AC-24, pp. 913-921, 1979.\n\nExample\n\njulia> using LinearAlgebra\n\njulia> A = [-6. -2. 1.; 5. 1. -1; -4. -2. -1.]\n3×3 Array{Float64,2}:\n -6.0  -2.0   1.0\n  5.0   1.0  -1.0\n -4.0  -2.0  -1.0\n\njulia> G = [1. 0. 0.; 0. 5. 0.; 0. 0. 10.]\n3×3 Array{Float64,2}:\n 1.0  0.0   0.0\n 0.0  5.0   0.0\n 0.0  0.0  10.0\n\njulia> X, CLSEIG = arec(A,G,2I);\n\njulia> X\n3×3 Array{Float64,2}:\n  0.459589   0.333603   -0.144406\n  0.333603   0.65916    -0.0999216\n -0.144406  -0.0999216   0.340483\n\njulia> A'*X+X*A-X*G*X+2I\n3×3 Array{Float64,2}:\n  2.22045e-16  4.44089e-16  -1.77636e-15\n  4.44089e-16  6.66134e-16   1.11022e-16\n -1.77636e-15  1.11022e-16  -1.33227e-15\n\njulia> CLSEIG\n3-element Array{Complex{Float64},1}:\n -4.411547592296008 + 2.4222082620381102im\n -4.411547592296008 - 2.4222082620381102im\n -4.337128244724371 + 0.0im\n\njulia> eigvals(A-G*X)\n3-element Array{Complex{Float64},1}:\n -4.4115475922960075 - 2.4222082620381076im\n -4.4115475922960075 + 2.4222082620381076im\n  -4.337128244724374 + 0.0im\n\n\n\n\n\narec(A, B, R, Q, S; as = false, rtol::Real = nϵ, orth = false) -> (X, EVALS, F, Z)\n\nComputes X, the hermitian/symmetric stabilizing solution (if as = false) or  anti-stabilizing solution (if as = true) of the continuous-time algebraic Riccati equation\n\n A'X + XA - (XB+S)R^(-1)(B'X+S') + Q = 0,\n\nwhere R and Q are hermitian/symmetric matrices or uniform scaling operators such that R is nonsingular.  Scalar-valued R and Q are interpreted as appropriately sized uniform scaling operators R*I and Q*I. S, if not specified, is set to S = zeros(size(B)).  \n\nBy default, the lower bound for the 1-norm reciprocal condition number rtol is n*ϵ, where n is the order of A  and ϵ is the machine epsilon of the element type of A. \n\nEVALS is a vector containing the (stable or anti-stable) eigenvalues of A-BF. F is the stabilizing or anti-stabilizing gain matrix F = R^(-1)(B'X+S'). Z = [ U; V; W ] is a basis for the relevant stable/anti-stable deflating subspace such that X = V/U and F = -W/U.  An orthogonal basis Z can be determined, with an increased computational cost, by setting orth = true.\n\nReference: Laub, A.J., A Schur Method for Solving Algebraic Riccati equations. IEEE Trans. Auto. Contr., AC-24, pp. 913-921, 1979.\n\nExample\n\njulia> using LinearAlgebra\n\njulia> A = [-6. -2. 1.; 5. 1. -1; -4. -2. -1.]\n3×3 Array{Float64,2}:\n -6.0  -2.0   1.0\n  5.0   1.0  -1.0\n -4.0  -2.0  -1.0\n\njulia> B = [1. 2.; 2. 0.; 0. 1.]\n3×2 Array{Float64,2}:\n 1.0  2.0\n 2.0  0.0\n 0.0  1.0\n\njulia> R = [1. 0.; 0. 5.]\n2×2 Array{Float64,2}:\n 1.0  0.0\n 0.0  5.0\n\njulia> X, CLSEIG, F = arec(A,B,R,2I);\n\njulia> X\n3×3 Array{Float64,2}:\n  0.522588   0.303007  -0.327227\n  0.303007   0.650895  -0.132608\n -0.327227  -0.132608   0.629825\n\njulia> A'*X+X*A-X*B*inv(R)*B'*X+2I\n3×3 Array{Float64,2}:\n -2.66454e-15  -1.55431e-15   8.88178e-16\n -1.55431e-15   2.22045e-15  -2.9976e-15\n  9.99201e-16  -2.9976e-15    4.44089e-16\n\njulia> CLSEIG\n3-element Array{Complex{Float64},1}:\n   -4.37703628399912 + 2.8107164873731247im\n   -4.37703628399912 - 2.8107164873731247im\n -1.8663764577096091 + 0.0im\n\njulia> eigvals(A-B*F)\n3-element Array{Complex{Float64},1}:\n  -4.377036283999118 - 2.8107164873731234im\n  -4.377036283999118 + 2.8107164873731234im\n -1.8663764577096063 + 0.0im\n\n\n\n\n\narec(A, B, G, R, Q, S; as = false, rtol::Real = nϵ, orth = false) -> (X, EVALS, F, Z)\n\nComputes X, the hermitian/symmetric stabilizing solution (if as = false) or  anti-stabilizing solution (if as = true) of the continuous-time algebraic Riccati equation\n\n A'X + XA - XGX - (XB+S)R^(-1)(B'X+S') + Q = 0,\n\nwhere G, R and Q are hermitian/symmetric matrices or uniform scaling operators such that R is nonsingular.  Scalar-valued G, R and Q are interpreted as appropriately sized uniform scaling operators G*I, R*I and Q*I.\n\nBy default, the lower bound for the 1-norm reciprocal condition number rtol is n*ϵ, where n is the order of A  and ϵ is the machine epsilon of the element type of A. \n\nEVALS is a vector containing the (stable or anti-stable) eigenvalues of A-BF-GX. F is the stabilizing or anti-stabilizing gain matrix F = R^(-1)(B'X+S'). Z = [ U; V; W ] is a basis for the relevant stable/anti-stable deflating subspace such that X = V/U and F = -W/U.  An orthogonal basis Z can be determined, with an increased computational cost, by setting orth = true.\n\nReference: Laub, A.J., A Schur Method for Solving Algebraic Riccati equations. IEEE Trans. Auto. Contr., AC-24, pp. 913-921, 1979.\n\n\n\n\n\n","category":"function"},{"location":"riccati.html#MatrixEquations.ared","page":"Riccati Matrix Equation Solvers","title":"MatrixEquations.ared","text":"ared(A, B, R, Q, S; as = false, rtol::Real = nϵ) -> (X, EVALS, F, Z)\n\nCompute X, the hermitian/symmetric stabilizing solution (if as = false) or  anti-stabilizing solution (if as = true) of the discrete-time algebraic Riccati equation\n\nA'XA - X - (A'XB+S)(R+B'XB)^(-1)(B'XA+S') + Q = 0,\n\nwhere R and Q are hermitian/symmetric matrices. Scalar-valued R and Q are interpreted as appropriately sized uniform scaling operators R*I and Q*I. S, if not specified, is set to S = zeros(size(B)).  \n\nBy default, the lower bound for the 1-norm reciprocal condition number rtol is n*ϵ, where n is the order of A  and ϵ is the machine epsilon of the element type of A. \n\nEVALS is a vector containing the (stable) eigenvalues of A-BF. F is the stabilizing gain matrix F = (R+B'XB)^(-1)(B'XA+S'). Z = [ U; V; W ] is an orthogonal basis for the relevant stable/anti-stable deflating subspace such that X = V/(EU) and F = -W/U. \n\nReference: W.F. Arnold, III and A.J. Laub, Generalized Eigenproblem Algorithms and Software for Algebraic Riccati Equations, Proc. IEEE, 72:1746-1754, 1984.\n\nExample\n\njulia> using LinearAlgebra\n\njulia> A = [ 0. 1.; 0. 0. ]\n2×2 Array{Float64,2}:\n 0.0  1.0\n 0.0  0.0\n\njulia> B = [ 0.; sqrt(2.) ]\n2-element Array{Float64,1}:\n 0.0\n 1.4142135623730951\n\njulia> R = 1.\n1.0\n\njulia> Q = [ 1. -1.; -1. 1. ]\n2×2 Array{Float64,2}:\n  1.0  -1.0\n -1.0   1.0\n\njulia> X, CLSEIG, F = ared(A,B,R,Q);\n\njulia> X\n2×2 Array{Float64,2}:\n  1.0  -1.0\n -1.0   1.5\n\njulia> A'*X*A-X-A'*X*B*inv(R+B'*X*B)*B'*X*A+Q\n2×2 Array{Float64,2}:\n  0.0          -3.33067e-16\n -3.33067e-16   8.88178e-16\n\njulia> CLSEIG\n2-element Array{Complex{Float64},1}:\n 0.4999999999999998 - 0.0im\n               -0.0 - 0.0im\n\njulia> eigvals(A-B*F)\n2-element Array{Float64,1}:\n -2.7755575615628914e-16\n  0.5\n\n\n\n\n\n","category":"function"},{"location":"riccati.html#Generalized-Riccati-Matrix-Equations-1","page":"Riccati Matrix Equation Solvers","title":"Generalized Riccati Matrix Equations","text":"","category":"section"},{"location":"riccati.html#","page":"Riccati Matrix Equation Solvers","title":"Riccati Matrix Equation Solvers","text":"garec\ngared","category":"page"},{"location":"riccati.html#MatrixEquations.garec","page":"Riccati Matrix Equation Solvers","title":"MatrixEquations.garec","text":"garec(A, E, G, Q = 0; as = false, rtol::Real = nϵ) -> (X, EVALS, Z)\n\nCompute X, the hermitian/symmetric stabilizing solution (if as = false) or  anti-stabilizing solution (if as = true) of the generalized continuous-time algebraic Riccati equation\n\nA'XE + E'XA - E'XGXE + Q = 0,\n\nwhere G and Q are hermitian/symmetric matrices or uniform scaling operators and E is a nonsingular matrix. Scalar-valued G and Q are interpreted as appropriately sized uniform scaling operators G*I and Q*I.\n\nBy default, the lower bound for the 1-norm reciprocal condition number rtol is n*ϵ, where n is the order of A  and ϵ is the machine epsilon of the element type of A. \n\nEVALS is a vector containing the (stable or anti-stable) generalized eigenvalues of the pair (A-GXE,E). Z = [ U; V ] is an orthogonal basis for the stable/anti-stable deflating subspace such that X = V/(EU). \n\nReference: W.F. Arnold, III and A.J. Laub, Generalized Eigenproblem Algorithms and Software for Algebraic Riccati Equations, Proc. IEEE, 72:1746-1754, 1984.\n\n\n\n\n\ngarec(A, E, B, R, Q, S; as = false, rtol::Real = nϵ) -> (X, EVALS, F, Z)\n\nCompute X, the hermitian/symmetric stabilizing solution (if as = false) or  anti-stabilizing solution (if as = true) of the generalized continuous-time algebraic Riccati equation\n\nA'XE + E'XA - (E'XB+S)R^(-1)(B'XE+S') + Q = 0,\n\nwhere R and Q are hermitian/symmetric matrices such that R is nonsingular, and E is a nonsingular matrix. Scalar-valued R and Q are interpreted as appropriately sized uniform scaling operators R*I and Q*I. S, if not specified, is set to S = zeros(size(B)).  \n\nBy default, the lower bound for the 1-norm reciprocal condition number rtol is n*ϵ, where n is the order of A  and ϵ is the machine epsilon of the element type of A. \n\nEVALS is a vector containing the (stable or anti-stable) generalized eigenvalues of the pair (A-BF,E). F is the stabilizing/anti-stabilizing gain matrix F = R^(-1)(B'XE+S'). Z = [ U; V; W ] is an orthogonal basis for the relevant stable/anti-stable deflating subspace such that X = V/(EU) and F = -W/U. \n\nReference: W.F. Arnold, III and A.J. Laub, Generalized Eigenproblem Algorithms and Software for Algebraic Riccati Equations, Proc. IEEE, 72:1746-1754, 1984.\n\nExample\n\njulia> using LinearAlgebra\n\njulia> A = [-6. -2. 1.; 5. 1. -1; -4. -2. -1.]\n3×3 Array{Float64,2}:\n -6.0  -2.0   1.0\n  5.0   1.0  -1.0\n -4.0  -2.0  -1.0\n\njulia> E = [10. 3. 0.; 0. 5. -1.; 0. 0. 10.]\n3×3 Array{Float64,2}:\n 10.0  3.0   0.0\n  0.0  5.0  -1.0\n  0.0  0.0  10.0\n\njulia> B = [1. 2.; 2. 0.; 0. 1.]\n3×2 Array{Float64,2}:\n 1.0  2.0\n 2.0  0.0\n 0.0  1.0\n\njulia> R = [1. 0.; 0. 5.]\n2×2 Array{Float64,2}:\n 1.0  0.0\n 0.0  5.0\n\njulia> X, CLSEIG, F = garec(A,E,B,R,2I);\n\njulia> X\n3×3 Array{Float64,2}:\n  0.0502214   0.0284089   -0.0303703\n  0.0284089   0.111219    -0.00259162\n -0.0303703  -0.00259162   0.0618395\n\njulia> A'*X*E+E'*X*A-E'*X*B*inv(R)*B'*X*E+2I\n3×3 Array{Float64,2}:\n  1.55431e-15  -1.9984e-15   -3.33067e-15\n -1.77636e-15   1.33227e-15  -3.33067e-15\n -2.88658e-15  -3.21965e-15   1.11022e-15\n\njulia> CLSEIG\n3-element Array{Complex{Float64},1}:\n  -0.6184265391601464 + 0.2913286844595737im\n  -0.6184265391601464 - 0.2913286844595737im\n -0.21613059964451786 + 0.0im\n\njulia> eigvals(A-B*F,E)\n3-element Array{Complex{Float64},1}:\n -0.6184265391601462 - 0.29132868445957383im\n -0.6184265391601462 + 0.2913286844595739im\n  -0.216130599644518 + 0.0im\n\n\n\n\n\ngarec(A, E, B, G, R, Q, S; as = false, rtol::Real = nϵ) -> (X, EVALS, F, Z)\n\nCompute X, the hermitian/symmetric stabilizing solution (if as = false) or  anti-stabilizing solution (if as = true) of the generalized continuous-time algebraic Riccati equation\n\nA'XE + E'XA - E'XGXE - (E'XB+S)R^(-1)(B'XE+S') + Q = 0,\n\nwhere G, Q and R are hermitian/symmetric matrices such that R is nonsingular, and E is a nonsingular matrix. Scalar-valued G, R and Q are interpreted as appropriately sized uniform scaling operators G*I, R*I and Q*I.\n\nBy default, the lower bound for the 1-norm reciprocal condition number rtol is n*ϵ, where n is the order of A  and ϵ is the machine epsilon of the element type of A. \n\nEVALS is a vector containing the (stable or anti-stable) generalized eigenvalues of the pair (A-BF-GXE,E). F is the stabilizing/anti-stabilizing gain matrix F = R^(-1)(B'XE+S'). Z = [ U; V; W ] is an orthogonal basis for the relevant stable/anti-stable deflating subspace such that X = V/(EU) and F = -W/U. \n\nReference: W.F. Arnold, III and A.J. Laub, Generalized Eigenproblem Algorithms and Software for Algebraic Riccati Equations, Proc. IEEE, 72:1746-1754, 1984.\n\n\n\n\n\n","category":"function"},{"location":"riccati.html#MatrixEquations.gared","page":"Riccati Matrix Equation Solvers","title":"MatrixEquations.gared","text":"gared(A, E, B, R, Q, S; as = false, rtol::Real = nϵ) -> (X, EVALS, F, Z)\n\nCompute X, the hermitian/symmetric stabilizing solution (if as = false) or  anti-stabilizing solution (if as = true) of the generalized discrete-time algebraic Riccati equation\n\nA'XA - E'XE - (A'XB+S)(R+B'XB)^(-1)(B'XA+S') + Q = 0,\n\nwhere R and Q are hermitian/symmetric matrices, and E ist non-singular. Scalar-valued R and Q are interpreted as appropriately sized uniform scaling operators R*I and Q*I. S, if not specified, is set to S = zeros(size(B)).  \n\nBy default, the lower bound for the 1-norm reciprocal condition number rtol is n*ϵ, where n is the order of A  and ϵ is the machine epsilon of the element type of A. \n\nEVALS is a vector containing the (stable or anti-stable) generalized eigenvalues of the pair (A-BF,E). F is the stabilizing/anti-stabilizing gain matrix F = (R+B'XB)^(-1)(B'XA+S'). Z = [ U; V; W ] is an orthogonal basis for the relevant stable/anti-stable deflating subspace such that X = V/(EU) and F = -W/U. \n\nReference: W.F. Arnold, III and A.J. Laub, Generalized Eigenproblem Algorithms and Software for Algebraic Riccati Equations, Proc. IEEE, 72:1746-1754, 1984.\n\nExample\n\njulia> using LinearAlgebra\n\njulia> A = [-6. -2. 1.; 5. 1. -1; -4. -2. -1.]\n3×3 Array{Float64,2}:\n -6.0  -2.0   1.0\n  5.0   1.0  -1.0\n -4.0  -2.0  -1.0\n\njulia> E = [10. 3. 0.; 0. 5. -1.; 0. 0. 10.]\n3×3 Array{Float64,2}:\n 10.0  3.0   0.0\n  0.0  5.0  -1.0\n  0.0  0.0  10.0\n\njulia> B = [1. 2.; 2. 0.; 0. 1.]\n3×2 Array{Float64,2}:\n 1.0  2.0\n 2.0  0.0\n 0.0  1.0\n\njulia> R = [1. 0.; 0. 5.]\n2×2 Array{Float64,2}:\n 1.0  0.0\n 0.0  5.0\n\njulia> X, CLSEIG, F = gared(A,E,B,R,2I);\n\njulia> X\n3×3 Array{Float64,2}:\n  0.065865   -0.0147205  -0.0100407\n -0.0147205   0.0885939   0.0101422\n -0.0100407   0.0101422   0.0234425\n\njulia> A'*X*A-E'*X*E-A'*X*B*inv(R+B'*X*B)*B'*X*A+2I\n3×3 Array{Float64,2}:\n -1.33227e-15  -2.48412e-15   1.38778e-16\n -2.498e-15    -4.44089e-16  -6.50521e-16\n  1.80411e-16  -5.91541e-16  -1.33227e-15\n\njulia> CLSEIG\n3-element Array{Complex{Float64},1}:\n  -0.084235615751339 - 0.0im\n  -0.190533552034239 - 0.0im\n -0.5238922629921539 - 0.0im\n\njulia> eigvals(A-B*F,E)\n3-element Array{Float64,1}:\n -0.5238922629921539 \n -0.19053355203423886\n -0.08423561575133902\n\n\n\n\n\n","category":"function"},{"location":"meoperators.html#Linear-Operators-Related-to-Matrix-Equation-Solvers-1","page":"Linear Operators Related to Matrix Equation Solvers","title":"Linear Operators Related to Matrix Equation Solvers","text":"","category":"section"},{"location":"meoperators.html#Lyapunov-Operators-1","page":"Linear Operators Related to Matrix Equation Solvers","title":"Lyapunov Operators","text":"","category":"section"},{"location":"meoperators.html#","page":"Linear Operators Related to Matrix Equation Solvers","title":"Linear Operators Related to Matrix Equation Solvers","text":"lyapop\ninvlyapop\ninvlyapsop","category":"page"},{"location":"meoperators.html#MatrixEquations.lyapop","page":"Linear Operators Related to Matrix Equation Solvers","title":"MatrixEquations.lyapop","text":"L = lyapop(A; disc = false, her = false)\n\nDefine, for an n x n matrix A, the continuous Lyapunov operator L:X -> AX+XA' if disc = false or the discrete Lyapunov operator L:X -> AXA'-X if disc = true. If her = false the Lyapunov operator L:X -> Y maps general square matrices X into general square matrices Y, and the associated matrix M = Matrix(L) is  n^2 times n^2. If her = true the Lyapunov operator L:X -> Y maps symmetric/Hermitian matrices X into symmetric/Hermitian matrices Y, and the associated matrix M = Matrix(L) is  n(n+1)2 times n(n+1)2. For the definitions of the Lyapunov operators see:\n\nM. Konstantinov, V. Mehrmann, P. Petkov. On properties of Sylvester and Lyapunov operators. Linear Algebra and its Applications 312:35–71, 2000.\n\n\n\n\n\nL = lyapop(A, E; disc = false, her = false)\n\nDefine, for a pair (A,E) of n x n matrices, the continuous Lyapunov operator L:X -> AXE'+EXA' if disc = false or the discrete Lyapunov operator L:X -> AXA'-EXE' if disc = true. If her = false the Lyapunov operator L:X -> Y maps general square matrices X into general square matrices Y, and the associated matrix M = Matrix(L) is  n^2 times n^2. If her = true the Lyapunov operator L:X -> Y maps symmetric/Hermitian matrices X into symmetric/Hermitian matrices Y, and the associated M = Matrix(L) is a n(n+1)2 times n(n+1)2. For the definitions of the Lyapunov operators see:\n\nM. Konstantinov, V. Mehrmann, P. Petkov. On properties of Sylvester and Lyapunov operators. Linear Algebra and its Applications 312:35–71, 2000.\n\n\n\n\n\n","category":"function"},{"location":"meoperators.html#MatrixEquations.invlyapop","page":"Linear Operators Related to Matrix Equation Solvers","title":"MatrixEquations.invlyapop","text":"LINV = invlyapop(A; disc = false, her = false)\n\nDefine LINV, the inverse of the continuous Lyapunov operator L:X -> AX+XA' for disc = false or the inverse of the discrete Lyapunov operator L:X -> AXA'-X for disc = true, where A is an n x n matrix. If her = false the inverse Lyapunov operator LINV:Y -> X maps general square matrices Y into general square matrices X, and the associated matrix M = Matrix(LINV) is  n^2 times n^2. If her = true the inverse Lyapunov operator LINV:Y -> X maps symmetric/Hermitian matrices Y into symmetric/Hermitian matrices X, and the associated matrix M = Matrix(LINV) is  n(n+1)2 times n(n+1)2. For the definitions of the Lyapunov operators see:\n\nM. Konstantinov, V. Mehrmann, P. Petkov. On properties of Sylvester and Lyapunov operators. Linear Algebra and its Applications 312:35–71, 2000.\n\n\n\n\n\nLINV = invlyapop(A, E; disc = false, her = false)\n\nDefine LINV, the inverse of the continuous Lyapunov operator L:X -> AXE'+EXA' for disc = false or the inverse of the discrete Lyapunov operator L:X -> AXA'-EXE' for disc = true, where (A,E) is a pair of n x n matrices. If her = false the inverse Lyapunov operator LINV:Y -> X maps general square matrices Y into general square matrices X, and the associated matrix M = Matrix(LINV) is  n^2 times n^2. If her = true the inverse Lyapunov operator LINV:Y -> X maps symmetric/Hermitian matrices Y into symmetric/Hermitian matrices X, and the associated matrix M = Matrix(LINV) is  n(n+1)2 times n(n+1)2. For the definitions of the Lyapunov operators see:\n\nM. Konstantinov, V. Mehrmann, P. Petkov. On properties of Sylvester and Lyapunov operators. Linear Algebra and its Applications 312:35–71, 2000.\n\n\n\n\n\n","category":"function"},{"location":"meoperators.html#MatrixEquations.invlyapsop","page":"Linear Operators Related to Matrix Equation Solvers","title":"MatrixEquations.invlyapsop","text":"LINV = invlyapsop(A; disc = false, her = false)\n\nDefine LINV, the inverse of the continuous Lyapunov operator L:X -> AX+XA' for disc = false or the inverse of the discrete Lyapunov operator L:X -> AXA'-X for disc = true, where A is an n x n matrix in Schur form. If her = false the inverse Lyapunov operator LINV:Y -> X maps general square matrices Y into general square matrices X, and the associated matrix M = Matrix(LINV) is  n^2 times n^2. If her = true the inverse Lyapunov operator LINV:Y -> X maps symmetric/Hermitian matrices Y into symmetric/Hermitian matrices X, and the associated matrix M = Matrix(LINV) is  n(n+1)2 times n(n+1)2. For the definitions of the Lyapunov operators see:\n\nM. Konstantinov, V. Mehrmann, P. Petkov. On properties of Sylvester and Lyapunov operators. Linear Algebra and its Applications 312:35–71, 2000.\n\n\n\n\n\nLINV = invlyapsop(A, E; disc = false, her = false)\n\nDefine LINV, the inverse of the continuous Lyapunov operator L:X -> AXE'+EXA' for disc = false or the inverse of the discrete Lyapunov operator L:X -> AXA'-EXE' for disc = true, where (A,E) is a pair of n x n matrices in generalized Schur form. If her = false the inverse Lyapunov operator LINV:Y -> X maps general square matrices Y into general square matrices X, and the associated matrix M = Matrix(LINV) is  n^2 times n^2. If her = true the inverse Lyapunov operator LINV:Y -> X maps symmetric/Hermitian matrices Y into symmetric/Hermitian matrices X, and the associated matrix M = Matrix(LINV) is  n(n+1)2 times n(n+1)2. For the definitions of the Lyapunov operators see:\n\nM. Konstantinov, V. Mehrmann, P. Petkov. On properties of Sylvester and Lyapunov operators. Linear Algebra and its Applications 312:35–71, 2000.\n\n\n\n\n\n","category":"function"},{"location":"meoperators.html#Sylvester-Operators-1","page":"Linear Operators Related to Matrix Equation Solvers","title":"Sylvester Operators","text":"","category":"section"},{"location":"meoperators.html#","page":"Linear Operators Related to Matrix Equation Solvers","title":"Linear Operators Related to Matrix Equation Solvers","text":"sylvop\ninvsylvop\ninvsylvsop","category":"page"},{"location":"meoperators.html#MatrixEquations.sylvop","page":"Linear Operators Related to Matrix Equation Solvers","title":"MatrixEquations.sylvop","text":"M = sylvop(A, B; disc = false)\n\nDefine the continuous Sylvester operator M: X -> AX+XB if disc = false or the discrete Sylvester operator M: X -> AXB+X if disc = true, where A and B are square matrices.\n\n\n\n\n\nM = sylvop(A, B, C, D)\n\nDefine the generalized Sylvester operator M: X -> AXB+CXD, where (A,C) and (B,D) a pairs of square matrices.\n\n\n\n\n\n","category":"function"},{"location":"meoperators.html#MatrixEquations.invsylvop","page":"Linear Operators Related to Matrix Equation Solvers","title":"MatrixEquations.invsylvop","text":"MINV = invsylvop(A, B; disc = false)\n\nDefine MINV, the inverse of the continuous Sylvester operator  M: X -> AX+XB if disc = false or of the discrete Sylvester operator M: X -> AXB+X if disc = true, where A and B are square matrices.\n\n\n\n\n\nMINV = invsylvop(A, B, C, D)\n\nDefine MINV, the inverse of the generalized Sylvester operator M: X -> AXB+CXD,  where (A,C) and (B,D) a pairs of square matrices.\n\n\n\n\n\n","category":"function"},{"location":"meoperators.html#MatrixEquations.invsylvsop","page":"Linear Operators Related to Matrix Equation Solvers","title":"MatrixEquations.invsylvsop","text":"MINV = invsylvsop(A, B; disc = false)\n\nDefine MINV, the inverse of the continuous Sylvester operator  M: X -> AX+XB if disc = false or of the discrete Sylvester operator M: X -> AXB+X if disc = true, where A and B are square matrices in Schur forms.\n\n\n\n\n\nMINV = invsylvsop(A, B, C, D; DBSchur = false)\n\nDefine MINV, the inverse of the generalized Sylvester operator M: X -> AXB+CXD, with the pairs (A,C) and (B,D) in generalized Schur forms. If DBSchur = true, the pair (D,B) is in generalized Schur form.\n\n\n\n\n\n","category":"function"},{"location":"meoperators.html#Sylvester-System-Operators-1","page":"Linear Operators Related to Matrix Equation Solvers","title":"Sylvester System Operators","text":"","category":"section"},{"location":"meoperators.html#","page":"Linear Operators Related to Matrix Equation Solvers","title":"Linear Operators Related to Matrix Equation Solvers","text":"sylvsysop\ninvsylvsysop\ninvsylvsyssop","category":"page"},{"location":"meoperators.html#MatrixEquations.sylvsysop","page":"Linear Operators Related to Matrix Equation Solvers","title":"MatrixEquations.sylvsysop","text":"M = sylvsysop(A, B, C, D)\n\nDefine the operator M: (X,Y) -> (AX+YB, CX+YD ),  where (A,C) and (B,D) a pairs of square matrices.\n\n\n\n\n\n","category":"function"},{"location":"meoperators.html#MatrixEquations.invsylvsysop","page":"Linear Operators Related to Matrix Equation Solvers","title":"MatrixEquations.invsylvsysop","text":"MINV = invsylvsysop(A, B, C, D)\n\nDefine MINV, the inverse of the linear operator M: (X,Y) -> (AX+YB, CX+YD ),  where (A,C) and (B,D) a pairs of square matrices.\n\n\n\n\n\n","category":"function"},{"location":"meoperators.html#MatrixEquations.invsylvsyssop","page":"Linear Operators Related to Matrix Equation Solvers","title":"MatrixEquations.invsylvsyssop","text":"MINV = invsylvsyssop(A, B, C, D)\n\nDefine MINV, the inverse of the linear operator M: (X,Y) -> (AX+YB, CX+YD), with the pairs (A,C) and (B,D) in generalized Schur forms.\n\n\n\n\n\n","category":"function"},{"location":"meoperators.html#Matrix-Transposition-Operator-1","page":"Linear Operators Related to Matrix Equation Solvers","title":"Matrix Transposition Operator","text":"","category":"section"},{"location":"meoperators.html#","page":"Linear Operators Related to Matrix Equation Solvers","title":"Linear Operators Related to Matrix Equation Solvers","text":"trmatop","category":"page"},{"location":"meoperators.html#MatrixEquations.trmatop","page":"Linear Operators Related to Matrix Equation Solvers","title":"MatrixEquations.trmatop","text":"M = trmatop(n, m)\n\nDefine the transposition operator M: X -> X' for all n x m matrices.\n\n\n\n\n\nM = trmatop(A)\n\nDefine the transposition operator M: X -> X' of all matrices of the size of A.\n\n\n\n\n\n","category":"function"},{"location":"sylvester.html#Sylvester-Matrix-Equation-Solvers-1","page":"Sylvester Matrix Equation Solvers","title":"Sylvester Matrix Equation Solvers","text":"","category":"section"},{"location":"sylvester.html#Standard-Sylvester-Matrix-Equations-1","page":"Sylvester Matrix Equation Solvers","title":"Standard Sylvester Matrix Equations","text":"","category":"section"},{"location":"sylvester.html#","page":"Sylvester Matrix Equation Solvers","title":"Sylvester Matrix Equation Solvers","text":"sylvc\nsylvcs!\nsylvd\nsylvds!","category":"page"},{"location":"sylvester.html#MatrixEquations.sylvc","page":"Sylvester Matrix Equation Solvers","title":"MatrixEquations.sylvc","text":"X = sylvc(A,B,C)\n\nSolve the continuous Sylvester matrix equation\n\n            AX + XB = C\n\nusing the Bartels-Stewart Schur form based approach. A and B are square matrices, and A and -B must not have common eigenvalues.\n\nThe following particular cases are also adressed:\n\nX = sylvc(α*I,B,C)  or  X = sylvc(α,B,C)\n\nSolve the matrix equation X(αI+B)  = C.\n\nX = sylvc(A,β*I,C)  or  X = sylvc(A,β,C)\n\nSolve the matrix equation (A+βI)X = C.\n\nX = sylvc(α*I,β*I,C)  or  sylvc(α,β,C)\n\nSolve the matrix equation (α+β)X = C.\n\nx = sylvc(α,β,γ)\n\nSolve the equation (α+β)x = γ.\n\nExample\n\njulia> A = [3. 4.; 5. 6.]\n2×2 Array{Float64,2}:\n 3.0  4.0\n 5.0  6.0\n\njulia> B = [1. 1.; 1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> C = [-1. -2.; 2. -1.]\n2×2 Array{Float64,2}:\n -1.0  -2.0\n  2.0  -1.0\n\njulia> X = sylvc(A, B, C)\n2×2 Array{Float64,2}:\n -4.46667   1.93333\n  3.73333  -1.8\n\njulia> A*X + X*B - C\n2×2 Array{Float64,2}:\n  2.66454e-15  1.77636e-15\n -3.77476e-15  4.44089e-16\n\n\n\n\n\n","category":"function"},{"location":"sylvester.html#MatrixEquations.sylvcs!","page":"Sylvester Matrix Equation Solvers","title":"MatrixEquations.sylvcs!","text":"sylvcs!(A,B,C; adjA = false, adjB = false)\n\nSolve the continuous Sylvester matrix equation\n\n            op(A)X + Xop(B) =  C,\n\nwhere op(A) = A or op(A) = A' if adjA = false or adjA = true, respectively, and op(B) = B or op(B) = B' if adjB = false or adjB = true, respectively. A and B are square matrices in Schur forms, and A and -B must not have common eigenvalues. C contains on output the solution X.\n\n\n\n\n\n","category":"function"},{"location":"sylvester.html#MatrixEquations.sylvd","page":"Sylvester Matrix Equation Solvers","title":"MatrixEquations.sylvd","text":"X = sylvd(A,B,C)\n\nSolve the discrete Sylvester matrix equation\n\n            AXB + X = C\n\nusing an extension of the Bartels-Stewart Schur form based approach. A and B are square matrices, and A and -B must not have common reciprocal eigenvalues.\n\nThe following particular cases are also adressed:\n\nX = sylvd(α*I,B,C)  or  X = sylvd(α,B,C)\n\nSolve the matrix equation X(αB+I)  = C.\n\nX = sylvd(A,β*I,C)   or  X = sylvd(A,β,C)\n\nSolve the matrix equation (βA+I)X = C.\n\nX = sylvd(α*I,β*I,C)  or  X = sylvd(α,β,C)\n\nSolve the matrix equation (αβ+1)X = C.\n\nx = sylvd(α,β,γ)\n\nSolve the equation (αβ+1)x = γ.\n\nExample\n\njulia> A = [3. 4.; 5. 6.]\n2×2 Array{Float64,2}:\n 3.0  4.0\n 5.0  6.0\n\njulia> B = [1. 1.; 1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> C = [-1. -2.; 2. -1.]\n2×2 Array{Float64,2}:\n -1.0  -2.0\n  2.0  -1.0\n   \njulia> X = sylvd(A, B, C)\n2×2 Array{Float64,2}:\n -2.46667  -2.73333\n  2.4       1.86667\n\njulia> A*X*B + X - C\n2×2 Array{Float64,2}:\n  8.88178e-16   8.88178e-16\n -3.9968e-15   -5.55112e-15\n\n\n\n\n\n","category":"function"},{"location":"sylvester.html#MatrixEquations.sylvds!","page":"Sylvester Matrix Equation Solvers","title":"MatrixEquations.sylvds!","text":"sylvds!(A,B,C; adjA = false, adjB = false)\n\nSolve the discrete Sylvester matrix equation\n\n            op(A)Xop(B) + X =  C,\n\nwhere op(A) = A or op(A) = A' if adjA = false or adjA = true, respectively, and op(B) = B or op(B) = B' if adjB = false or adjB = true, respectively. A and B are square matrices in Schur forms, and A and -B must not have common reciprocal eigenvalues. C contains on output the solution X.\n\n\n\n\n\n","category":"function"},{"location":"sylvester.html#Generalized-Sylvester-Matrix-Equations-1","page":"Sylvester Matrix Equation Solvers","title":"Generalized Sylvester Matrix Equations","text":"","category":"section"},{"location":"sylvester.html#","page":"Sylvester Matrix Equation Solvers","title":"Sylvester Matrix Equation Solvers","text":"gsylv\ngsylvs!","category":"page"},{"location":"sylvester.html#MatrixEquations.gsylv","page":"Sylvester Matrix Equation Solvers","title":"MatrixEquations.gsylv","text":"X = gsylv(A,B,C,D,E)\n\nSolve the generalized Sylvester matrix equation\n\n          AXB + CXD = E\n\nusing a generalized Schur form based approach. A, B, C and D are square matrices. The pencils A-λC and D+λB must be regular and must not have common eigenvalues.\n\nThe following particular cases are also adressed:\n\nX = gsylv(A,B,E)\n\nSolve the generalized Sylvester matrix equation AXB  = E.\n\nX = gsylv(A,B,γ*I,E)  or  X = gsylv(A,B,γ,E)\n\nSolve the generalized Sylvester matrix equation AXB +γX = E.\n\nX = gsylv(A,B,γ*I,D,E)  or  X = gsylv(A,B,γ,D,E)\n\nSolve the generalized Sylvester matrix equation AXB +γXD = E.\n\nX = gsylv(A,B,C,δ*I,E)  or  X = gsylv(A,B,C,δ,E)\n\nSolve the generalized Sylvester matrix equation AXB +CXδ = E.\n\nExample\n\njulia> A = [3. 4.; 5. 6.]\n2×2 Array{Float64,2}:\n 3.0  4.0\n 5.0  6.0\n\njulia> B = [1. 1.; 1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> C = [-1. -2.; 2. -1.]\n2×2 Array{Float64,2}:\n -1.0  -2.0\n  2.0  -1.0\n\njulia> D = [1. -2.; -2. -1.]\n2×2 Array{Float64,2}:\n  1.0  -2.0\n -2.0  -1.0\n\njulia> E = [1. -1.; -2. 2.]\n2×2 Array{Float64,2}:\n  1.0  -1.0\n -2.0   2.0\n\njulia> X = gsylv(A, B, C, D, E)\n2×2 Array{Float64,2}:\n -0.52094   -0.0275792\n -0.168539   0.314607\n \njulia> A*X*B + C*X*D - E\n2×2 Array{Float64,2}:\n 4.44089e-16  8.88178e-16\n 6.66134e-16  0.0\n\n\n\n\n\n","category":"function"},{"location":"sylvester.html#MatrixEquations.gsylvs!","page":"Sylvester Matrix Equation Solvers","title":"MatrixEquations.gsylvs!","text":"X = gsylvs!(A,B,C,D,E; adjAC=false, adjBD=false, CASchur = false, DBSchur = false)\n\nSolve the generalized Sylvester matrix equation\n\n            op1(A)Xop2(B) + op1(C)Xop2(D) = E,\n\nwhere A, B, C and D are square matrices, and\n\nop1(A) = A and op1(C) = C if adjAC = false;\n\nop1(A) = A' and op1(C) = C' if adjAC = true;\n\nop2(B) = B and op2(D) = D if adjBD = false;\n\nop2(B) = B' and op2(D) = D' if adjBD = true.\n\nThe matrix pair (A,C) is in a generalized real or complex Schur form. The matrix pair (B,D) is in a generalized real or complex Schur form if DBSchur = false or the matrix pair (D,B) is in a generalized real or complex Schur form if DBSchur = true. The pencils A-λC and D+λB must be regular and must not have common eigenvalues.\n\n\n\n\n\n","category":"function"},{"location":"sylvester.html#Sylvester-Systems-of-Matrix-Equation-1","page":"Sylvester Matrix Equation Solvers","title":"Sylvester Systems of Matrix Equation","text":"","category":"section"},{"location":"sylvester.html#","page":"Sylvester Matrix Equation Solvers","title":"Sylvester Matrix Equation Solvers","text":"sylvsys\nsylvsyss!\ndsylvsys\ndsylvsyss!","category":"page"},{"location":"sylvester.html#MatrixEquations.sylvsys","page":"Sylvester Matrix Equation Solvers","title":"MatrixEquations.sylvsys","text":"(X,Y) = sylvsys(A,B,C,D,E,F)\n\nSolve the Sylvester system of matrix equations\n\n            AX + YB = C\n            DX + YE = F,\n\nwhere (A,D), (B,E) are pairs of square matrices of the same size. The pencils A-λD and -B+λE must be regular and must not have common eigenvalues.\n\nExample\n\njulia> A = [3. 4.; 5. 6.]\n2×2 Array{Float64,2}:\n 3.0  4.0\n 5.0  6.0\n\njulia> B = [1. 1.; 1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> C = [-1. -2.; 2. -1.]\n2×2 Array{Float64,2}:\n -1.0  -2.0\n  2.0  -1.0\n\njulia> D = [1. -2.; -2. -1.]\n2×2 Array{Float64,2}:\n  1.0  -2.0\n -2.0  -1.0\n\njulia> E = [1. -1.; -2. 2.]\n2×2 Array{Float64,2}:\n  1.0  -1.0\n -2.0   2.0\n\njulia> F = [1. -1.; -2. 2.]\n2×2 Array{Float64,2}:\n  1.0  -1.0\n -2.0   2.0\n\njulia> X, Y = sylvsys(A, B, C, D, E, F);\n\njulia> X\n2×2 Array{Float64,2}:\n  1.388  -1.388\n -0.892   0.892\n\njulia> Y\n2×2 Array{Float64,2}:\n -1.788  0.192\n  0.236  0.176\n\njulia> A*X + Y*B - C\n2×2 Array{Float64,2}:\n  6.66134e-16  2.22045e-15\n -3.10862e-15  2.66454e-15\n\njulia> D*X + Y*E - F\n2×2 Array{Float64,2}:\n  1.33227e-15  -2.22045e-15\n -4.44089e-16   4.44089e-16\n\n\n\n\n\n","category":"function"},{"location":"sylvester.html#MatrixEquations.sylvsyss!","page":"Sylvester Matrix Equation Solvers","title":"MatrixEquations.sylvsyss!","text":"(X,Y) = sylvsyss!(A,B,C,D,E,F)\n\nSolve the Sylvester system of matrix equations\n\n            AX + YB = C\n            DX + YE = F,\n\nwhere (A,D), (B,E) are pairs of square matrices of the same size in generalized Schur forms. The pencils A-λD and -B+λE must be regular and must not have common eigenvalues. The computed solution (X,Y) is contained in (C,F).\n\nNote: This is an enhanced interface to the LAPACK.tgsyl! function to also cover the case when A, B, D and E are real matrices and C and F are complex matrices.\n\n\n\n\n\n","category":"function"},{"location":"sylvester.html#MatrixEquations.dsylvsys","page":"Sylvester Matrix Equation Solvers","title":"MatrixEquations.dsylvsys","text":"(X,Y) = dsylvsys(A,B,C,D,E,F)\n\nSolve the dual Sylvester system of matrix equations\n\n   AX + DY = C\n   XB + YE = F ,\n\nwhere (A,D), (B,E) are pairs of square matrices of the same size. The pencils A-λD and -B+λE must be regular and must not have common eigenvalues.\n\nExample\n\njulia> A = [3. 4.; 5. 6.]\n2×2 Array{Float64,2}:\n 3.0  4.0\n 5.0  6.0\n\njulia> B = [1. 1.; 1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> C = [-1. -2.; 2. -1.]\n2×2 Array{Float64,2}:\n -1.0  -2.0\n  2.0  -1.0\n\njulia> D = [1. -2.; -2. -1.]\n2×2 Array{Float64,2}:\n  1.0  -2.0\n -2.0  -1.0\n\njulia> E = [1. -1.; -2. 2.]\n2×2 Array{Float64,2}:\n  1.0  -1.0\n -2.0   2.0\n\njulia> F = [1. -1.; -2. 2.]\n2×2 Array{Float64,2}:\n  1.0  -1.0\n -2.0   2.0\n\njulia> X, Y = dsylvsys(A, B, C, D, E, F);\n\njulia> X\n2×2 Array{Float64,2}:\n  2.472  -1.648\n -1.848   1.232\n\njulia> Y\n2×2 Array{Float64,2}:\n -0.496  -0.336\n  0.264   0.824\n\njulia> A*X + D*Y - C\n2×2 Array{Float64,2}:\n  4.44089e-16  0.0\n -3.55271e-15  1.55431e-15\n \njulia> X*B + Y*E - F\n2×2 Array{Float64,2}:\n -8.88178e-16   0.0\n  8.88178e-16  -4.44089e-16\n\n\n\n\n\n","category":"function"},{"location":"sylvester.html#MatrixEquations.dsylvsyss!","page":"Sylvester Matrix Equation Solvers","title":"MatrixEquations.dsylvsyss!","text":"(X,Y) = dsylvsyss!(A,B,C,D,E,F)\n\nSolve the dual Sylvester system of matrix equations\n\nA'X + D'Y = C\nXB' + YE' = F,\n\nwhere (A,D), (B,E) are pairs of square matrices of the same size in generalized Schur forms. The pencils A-λD and -B+λE must be regular and must not have common eigenvalues. The computed solution (X,Y) is contained in (C,F).\n\n\n\n\n\n","category":"function"},{"location":"lyapunov.html#Lyapunov-Matrix-Equation-Solvers-1","page":"Lyapunov Matrix Equation Solvers","title":"Lyapunov Matrix Equation Solvers","text":"","category":"section"},{"location":"lyapunov.html#Continuous-time-Lyapunov-Matrix-Equations-1","page":"Lyapunov Matrix Equation Solvers","title":"Continuous-time Lyapunov Matrix Equations","text":"","category":"section"},{"location":"lyapunov.html#","page":"Lyapunov Matrix Equation Solvers","title":"Lyapunov Matrix Equation Solvers","text":"lyapc\nlyapcs!","category":"page"},{"location":"lyapunov.html#MatrixEquations.lyapc","page":"Lyapunov Matrix Equation Solvers","title":"MatrixEquations.lyapc","text":"X = lyapc(A, C)\n\nCompute X, the symmetric or hermitian solution of the continuous Lyapunov equation\n\n  AX + XA' + C = 0,\n\nwhere A is a square real or complex matrix and C is a symmetric or hermitian matrix. A must not have two eigenvalues α and β such that α+β = 0.\n\nThe following particular cases are also adressed:\n\nX = lyapc(α*I,C)  or  X = lyapc(α,C)\n\nSolve the matrix equation (α+α')X + C = 0.\n\nx = lyapc(α,γ)\n\nSolve the equation (α+α')x + γ = 0.\n\nExample\n\njulia> A = [3. 4.; 5. 6.]\n2×2 Array{Float64,2}:\n 3.0  4.0\n 5.0  6.0\n\njulia> C = [1. 1.; 1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> X = lyapc(A, C)\n2×2 Array{Float64,2}:\n  0.5  -0.5\n -0.5   0.25\n\njulia> A*X + X*A' + C\n2×2 Array{Float64,2}:\n -8.88178e-16   2.22045e-16\n  2.22045e-16  -4.44089e-16\n\n\n\n\n\nX = lyapc(A, E, C)\n\nCompute X, the symmetric or hermitian solution of the generalized continuous Lyapunov equation\n\n AXE' + EXA' + C = 0,\n\nwhere A and E are square real or complex matrices and C is a symmetric or hermitian matrix. The pencil A-λE must not have two eigenvalues α and β such that α+β = 0.\n\nThe following particular cases are also adressed:\n\nX = lyapc(A,β*I,C)  or  X = lyapc(A,β,C)\n\nSolve the matrix equation AXβ' + βXA' + C = 0.\n\nX = lyapc(α*I,E,C)  or  X = lyapc(α,E,C)\n\nSolve the matrix equation αXE' + EXα' + C = 0.\n\nX = lyapc(α*I,β*I,C)  or  X = lyapc(α,β,C)\n\nSolve the matrix equation (αβ'+α'β)X + C = 0.\n\nx = lyapc(α,β,γ)\n\nSolve the equation (αβ'+α'β)x + γ = 0.\n\nExample\n\njulia> A = [3. 4.; 5. 6.]\n2×2 Array{Float64,2}:\n 3.0  4.0\n 5.0  6.0\n\njulia> E = [ 1. 2.; 0. 1.]\n2×2 Array{Float64,2}:\n 1.0  2.0\n 0.0  1.0\n\njulia> C = [1. 1.; 1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> X = lyapc(A, E, C)\n2×2 Array{Float64,2}:\n -2.5   2.5\n  2.5  -2.25\n\njulia> A*X*E' + E*X*A' + C\n2×2 Array{Float64,2}:\n -5.32907e-15  -2.66454e-15\n -4.44089e-15   0.0\n\n\n\n\n\n","category":"function"},{"location":"lyapunov.html#MatrixEquations.lyapcs!","page":"Lyapunov Matrix Equation Solvers","title":"MatrixEquations.lyapcs!","text":"lyapcs!(A,C;adj = false)\n\nSolve the continuous Lyapunov matrix equation\n\n            op(A)X + Xop(A)' + C = 0,\n\nwhere op(A) = A if adj = false and op(A) = A' if adj = true. A is a square real matrix in a real Schur form, or a square complex matrix in a complex Schur form and C is a symmetric or hermitian matrix. A must not have two eigenvalues α and β such that α+β = 0. C contains on output the solution X.\n\n\n\n\n\nlyapcs!(A, E, C; adj = false)\n\nSolve the generalized continuous Lyapunov matrix equation\n\n            op(A)Xop(E)' + op(E)Xop(A)' + C = 0,\n\nwhere op(A) = A and op(E) = E if adj = false and op(A) = A' and op(E) = E' if adj = true. The pair (A,E) is in a generalized real or complex Schur form and C is a symmetric or hermitian matrix. The pencil A-λE must not have two eigenvalues α and β such that α+β = 0. The computed symmetric or hermitian solution X is contained in C.\n\n\n\n\n\n","category":"function"},{"location":"lyapunov.html#Discrete-time-Lyapunov-(Stein)-Matrix-Equations-1","page":"Lyapunov Matrix Equation Solvers","title":"Discrete-time Lyapunov (Stein) Matrix Equations","text":"","category":"section"},{"location":"lyapunov.html#","page":"Lyapunov Matrix Equation Solvers","title":"Lyapunov Matrix Equation Solvers","text":"lyapd\nlyapds!","category":"page"},{"location":"lyapunov.html#MatrixEquations.lyapd","page":"Lyapunov Matrix Equation Solvers","title":"MatrixEquations.lyapd","text":"X = lyapd(A, C)\n\nCompute X, the symmetric or hermitian solution of the discrete Lyapunov equation\n\n   AXA' - X + C = 0,\n\nwhere A is a square real or complex matrix and C is a symmetric or hermitian matrix. A must not have two eigenvalues α and β such that αβ = 1. The following particular cases are also adressed:\n\nX = lyapd(α*I,C)  or  X = lyapd(α,C)\n\nSolve the matrix equation (αα'-1)X + C = 0.\n\nx = lyapd(α,γ)\n\nSolve the equation (αα'-1)x + γ = 0.\n\nExample\n\njulia> A = [3. 4.; 5. 6.]\n2×2 Array{Float64,2}:\n 3.0  4.0\n 5.0  6.0\n\njulia> C = [1. 1.; 1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> X = lyapd(A, C)\n2×2 Array{Float64,2}:\n  0.2375  -0.2125\n -0.2125   0.1375\n\njulia> A*X*A' - X + C\n2×2 Array{Float64,2}:\n 5.55112e-16  6.66134e-16\n 2.22045e-16  4.44089e-16\n\n\n\n\n\nX = lyapd(A, E, C)\n\nCompute X, the symmetric or hermitian solution of the generalized discrete Lyapunov equation\n\n     AXA' - EXE' + C = 0,\n\nwhere A and E are square real or complex matrices and C is a symmetric or hermitian matrix. The pencil A-λE must not have two eigenvalues α and β such that αβ = 1. The following particular cases are also adressed:\n\nX = lyapd(A,β*I,C)  or  X = lyapd(A,β,C)\n\nSolve the matrix equation AXA' - βXβ' + C = 0.\n\nX = lyapd(α*I,E,C)  or  X = lyapd(α,E,C)\n\nSolve the matrix equation αXα' - EXE' + C = 0.\n\nX = lyapd(α*I,β*I,C)  or  X = lyapd(α,β,C)\n\nSolve the matrix equation (αα'-ββ')X + C = 0.\n\nx = lyapd(α,β,γ)\n\nSolve the equation (αα'-ββ')x + γ = 0.\n\nExample\n\njulia> A = [3. 4.; 5. 6.]\n2×2 Array{Float64,2}:\n 3.0  4.0\n 5.0  6.0\n\njulia> E = [ 1. 2.; 0. -1.]\n2×2 Array{Float64,2}:\n 1.0   2.0\n 0.0  -1.0\n\njulia> C = [1. 1.; 1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> X = lyapd(A, E, C)\n2×2 Array{Float64,2}:\n  1.775  -1.225\n -1.225   0.775\n \njulia> A*X*A' - E*X*E' + C\n2×2 Array{Float64,2}:\n -2.22045e-16  -4.44089e-16\n -1.33227e-15   1.11022e-15\n\n\n\n\n\n","category":"function"},{"location":"lyapunov.html#MatrixEquations.lyapds!","page":"Lyapunov Matrix Equation Solvers","title":"MatrixEquations.lyapds!","text":"lyapds!(A, C; adj = false)\n\nSolve the discrete Lyapunov matrix equation\n\n            op(A)Xop(A)' - X + C = 0,\n\nwhere op(A) = A if adj = false and op(A) = A' if adj = true. A is in a real or complex Schur form and C is a symmetric or hermitian matrix. A must not have two eigenvalues α and β such that αβ = 1. The computed symmetric or hermitian solution X is contained in C.\n\n\n\n\n\nlyapds!(A, E, C; adj = false)\n\nSolve the generalized discrete Lyapunov matrix equation\n\n            op(A)Xop(A)' - op(E)Xop(E)' + C = 0,\n\nwhere op(A) = A and op(E) = E if adj = false and op(A) = A' and op(E) = E' if adj = true. The pair (A,E) is in a generalized real or complex Schur form and C is a symmetric or hermitian matrix. The pencil A-λE must not have two eigenvalues α and β such that αβ = 1. The computed symmetric or hermitian solution X is contained in C.\n\n\n\n\n\n","category":"function"},{"location":"makeindex.html#Index-1","page":"Index","title":"Index","text":"","category":"section"},{"location":"makeindex.html#","page":"Index","title":"Index","text":"Pages = [\"lyapunov.md\", \"plyapunov.md\", \"riccati.md\", \"sylvester.md\", \"sylvkr.md\", \"condest.md\",\"meoperators.md\", \"lapackutil.md\" ]\nModule = [\"MatrixEquations\"]\nOrder = [:type, :function]","category":"page"},{"location":"lapackutil.html#Lapack-Utilities-1","page":"Lapack Utilities","title":"Lapack Utilities","text":"","category":"section"},{"location":"lapackutil.html#","page":"Lapack Utilities","title":"Lapack Utilities","text":"tgsyl!\nlanv2\nlag2\nladiv\nlacn2!","category":"page"},{"location":"lapackutil.html#MatrixEquations.LapackUtil.tgsyl!","page":"Lapack Utilities","title":"MatrixEquations.LapackUtil.tgsyl!","text":"tgsyl!(A, B, C, D, E, F) -> (C, F, scale)\n\nSolve the Sylvester system of matrix equations\n\n  AX - YB = scale*C\n  DX - YE = scale*F ,\n\nwhere X and Y are unknown matrices, the pairs (A, D), (B, E) and  (C, F) have the same sizes, and the pairs (A, D) and (B, E) are in generalized (real) Schur canonical form, i.e. A, B are upper quasi triangular and D, E are upper triangular. Returns X (overwriting C), Y (overwriting F) and scale.\n\ntgsyl!(trans, A, B, C, D, E, F) -> (C, F, scale)\n\nSolve for trans = 'T' and real matrices or for trans = 'C' and complex matrices,  the (adjoint) Sylvester system of matrix equations\n\n  A'X + D'Y = scale*C\n  XB' + YE' = scale*(-F) .\n\ntgsyl!('N', A, B, C, D, E, F) corresponds to the call tgsyl!(A, B, C, D, E, F).\n\nInterface to the LAPACK subroutines DTGSYL/STGSYL/ZTGSYL/CTGSYL.\n\n\n\n\n\n","category":"function"},{"location":"lapackutil.html#MatrixEquations.LapackUtil.lanv2","page":"Lapack Utilities","title":"MatrixEquations.LapackUtil.lanv2","text":"lanv2(A, B, C, D) -> (RT1R, RT1I, RT2R, RT2I, CS, SN)\n\nCompute the Schur factorization of a real 2-by-2 nonsymmetric matrix [A,B;C,D] in standard form. A, B, C, D are overwritten on output by the corresponding elements of the standardised Schur form. RT1R+im*RT1I and RT2R+im*RT2I are the resulting eigenvalues. CS and SN are the parameters of the rotation matrix. Interface to the LAPACK subroutines DLANV2/SLANV2.\n\n\n\n\n\n","category":"function"},{"location":"lapackutil.html#MatrixEquations.LapackUtil.lag2","page":"Lapack Utilities","title":"MatrixEquations.LapackUtil.lag2","text":"lag2(A, B, SAFMIN) -> (SCALE1, SCALE2, WR1, WR2, WI)\n\nCompute the eigenvalues of a 2-by-2 generalized real eigenvalue problem for the matrix pair (A,B), with scaling as necessary to avoid over-/underflow. SAFMIN is the smallest positive number s.t. 1/SAFMIN does not overflow. If WI = 0, WR1/SCALE1 and WR2/SCALE2 are the resulting real eigenvalues, while if WI <> 0, then (WR1+/-im*WI)/SCALE1 are the resulting complex eigenvalues. Interface to the LAPACK subroutines DLAG2/SLAG2.\n\n\n\n\n\n","category":"function"},{"location":"lapackutil.html#MatrixEquations.LapackUtil.ladiv","page":"Lapack Utilities","title":"MatrixEquations.LapackUtil.ladiv","text":"ladiv(A, B, C, D) -> (P, Q)\n\nPerform the complex division in real arithmetic\n\nP + iQ = displaystylefracA+iBC+iD\n\nby avoiding unnecessary overflow. Interface to the LAPACK subroutines DLADIV/SLADIV.\n\n\n\n\n\n","category":"function"},{"location":"lapackutil.html#MatrixEquations.LapackUtil.lacn2!","page":"Lapack Utilities","title":"MatrixEquations.LapackUtil.lacn2!","text":"lacn2!(V, X, ISGN, EST, KASE, ISAVE ) -> (EST, KASE )\n\nEstimate the 1-norm of a real linear operator A, using reverse communication by applying the operator or its transpose/adjoint to a vector. KASE is a parameter to control the norm evaluation process as follows. On the initial call, KASE should be 0. On an intermediate return, KASE will be 1 or 2, indicating whether the real vector X should be overwritten by A * X  or A' * X at the next call. On the final return, KASE will again be 0 and EST is an estimate (a lower bound) for the 1-norm of A. V is a real work vector, ISGN is an integer work vector and ISAVE is a 3-dimensional integer vector used to save information between the calls. Interface to the LAPACK subroutines DLACN2/SLACN2.\n\n\n\n\n\nlacn2!(V, X, EST, KASE, ISAVE ) -> (EST, KASE )\n\nEstimate the 1-norm of a complex linear operator A, using reverse communication by applying the operator or its adjoint to a vector. KASE is a parameter to control the norm evaluation process as follows. On the initial call, KASE should be 0. On an intermediate return, KASE will be 1 or 2, indicating whether the complex vector X should be overwritten by A * X  or A' * X at the next call. On the final return, KASE will again be 0 and EST is an estimate (a lower bound) for the 1-norm of A. V is a complex work vector and ISAVE is a 3-dimensional integer vector used to save information between the calls. Interface to the LAPACK subroutines ZLACN2/CLACN2.\n\n\n\n\n\n","category":"function"},{"location":"plyapunov.html#Positive-definite-Lyapunov-Matrix-Equation-Solvers-1","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"Positive-definite Lyapunov Matrix Equation Solvers","text":"","category":"section"},{"location":"plyapunov.html#Continuous-time-Lyapunov-Matrix-Equations-1","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"Continuous-time Lyapunov Matrix Equations","text":"","category":"section"},{"location":"plyapunov.html#","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"Positive-definite Lyapunov Matrix Equation Solvers","text":"plyapc\nplyapcs!","category":"page"},{"location":"plyapunov.html#MatrixEquations.plyapc","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"MatrixEquations.plyapc","text":"U = plyapc(A, B)\n\nCompute U, the upper triangular factor of the solution X = UU' of the continuous Lyapunov equation\n\n  AX + XA' + BB' = 0,\n\nwhere A is a square real or complex matrix and B is a matrix with the same number of rows as A. A must have only eigenvalues with negative real parts.\n\nU = plyapc(A', B')\n\nCompute U, the upper triangular factor of the solution X = U'U of the continuous Lyapunov equation\n\n  A'X + XA + B'B = 0,\n\nwhere A is a square real or complex matrix and B is a matrix with the same number of columns as A. A must have only eigenvalues with negative real parts.\n\nExample\n\njulia> using LinearAlgebra\n\njulia> A = [-2. 1.;-1. -2.]\n2×2 Array{Float64,2}:\n -2.0   1.0\n -1.0  -2.0\n\njulia> B = [1. 1. ;1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> U = plyapc(A,B)\n2×2 UpperTriangular{Float64,Array{Float64,2}}:\n 0.481812  0.801784\n  ⋅        0.935414\n\njulia> A*U*U'+U*U'*A'+B*B'\n2×2 Array{Float64,2}:\n 0.0          8.88178e-16\n 8.88178e-16  3.55271e-15\n\n\n\n\n\nU = plyapc(A, E, B)\n\nCompute U, the upper triangular factor of the solution X = UU' of the generalized continuous Lyapunov equation\n\n  AXE' + EXA' + BB' = 0,\n\nwhere A and E are square real or complex matrices and B is a matrix with the same number of rows as A. The pencil A - λE must have only eigenvalues with negative real parts.\n\nU = plyapc(A', E', B')\n\nCompute U, the upper triangular factor of the solution X = U'U of the generalized continuous Lyapunov equation\n\n  A'XE + E'XA + B'B = 0,\n\nwhere A and E are square real or complex matrices and B is a matrix with the same number of columns as A. The pencil A - λE must have only eigenvalues with negative real parts.\n\nExample\n\njulia> using LinearAlgebra\n\njulia> A = [-2. 1.;-1. -2.]\n2×2 Array{Float64,2}:\n -2.0   1.0\n -1.0  -2.0\n\njulia> E = [1. 0.; 1. 1.]\n2×2 Array{Float64,2}:\n 1.0  0.0\n 1.0  1.0\n\njulia> B = [1. 1. ;1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> U = plyapc(A,E,B)\n2×2 UpperTriangular{Float64,Array{Float64,2}}:\n 0.408248  0.730297\n  ⋅        0.547723\n\njulia> A*U*U'*E'+E*U*U'*A'+B*B'\n2×2 Array{Float64,2}:\n  0.0          -8.88178e-16\n -1.33227e-15  -2.66454e-15\n\n\n\n\n\n","category":"function"},{"location":"plyapunov.html#MatrixEquations.plyapcs!","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"MatrixEquations.plyapcs!","text":"plyapcs!(A,R;adj = false)\n\nSolve the positive continuous Lyapunov matrix equation\n\n            op(A)X + Xop(A)' + op(R)*op(R)' = 0\n\nfor X = op(U)*op(U)', where op(K) = K if adj = false and op(K) = K' if adj = true. A is a square real matrix in a real Schur form  or a square complex matrix in a complex Schur form and R is an upper triangular matrix. A must have only eigenvalues with negative real parts. R contains on output the solution U.\n\n\n\n\n\nplyapcs!(A,E,R;adj = false)\n\nSolve the generalized positive continuous Lyapunov matrix equation\n\n            op(A)Xop(E)' + op(E)*Xop(A)' + op(R)*op(R)' = 0\n\nfor X = op(U)*op(U)', where op(K) = K if adj = false and op(K) = K' if adj = true. The pair (A,E) is in a generalized real/complex Schur form and R is an upper triangular matrix. The pencil A-λE must have only eigenvalues with negative real parts. R contains on output the solution U.\n\n\n\n\n\n","category":"function"},{"location":"plyapunov.html#Discrete-time-Lyapunov-(Stein)-Matrix-Equations-1","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"Discrete-time Lyapunov (Stein) Matrix Equations","text":"","category":"section"},{"location":"plyapunov.html#","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"Positive-definite Lyapunov Matrix Equation Solvers","text":"plyapd\nplyapds!","category":"page"},{"location":"plyapunov.html#MatrixEquations.plyapd","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"MatrixEquations.plyapd","text":"U = plyapd(A, B)\n\nCompute U, the upper triangular factor of the solution X = UU' of the discrete Lyapunov equation\n\n  AXA' - X + BB' = 0,\n\nwhere A is a square real or complex matrix and B is a matrix with the same number of rows as A. A must have only eigenvalues with moduli less than one.\n\nU = plyapd(A', B')\n\nCompute U, the upper triangular factor of the solution X = U'U of the discrete Lyapunov equation\n\n  A'XA - X + B'B = 0,\n\nwhere A is a square real or complex matrix and B is a matrix with the same number of columns as A. A must have only eigenvalues with moduli less than one.\n\nExample\n\njulia> using LinearAlgebra\n\njulia> A = [-0.5 .1;-0.1 -0.5]\n2×2 Array{Float64,2}:\n -0.5   0.1\n -0.1  -0.5\n\njulia> B = [1. 1. ;1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> U = plyapd(A,B)\n2×2 UpperTriangular{Float64,Array{Float64,2}}:\n 0.670145  1.35277\n  ⋅        2.67962\n\njulia> A*U*U'*A'-U*U'+B*B'\n2×2 Array{Float64,2}:\n -4.44089e-16  4.44089e-16\n  4.44089e-16  1.77636e-15\n\n\n\n\n\nU = plyapd(A, E, B)\n\nCompute U, the upper triangular factor of the solution X = UU' of the generalized discrete Lyapunov equation\n\n  AXA' - EXE' + BB' = 0,\n\nwhere A and E are square real or complex matrices and B is a matrix with the same number of rows as A. The pencil A - λE must have only eigenvalues with moduli less than one.\n\nU = plyapd(A', E', B')\n\nCompute U, the upper triangular factor of the solution X = U'U of the generalized discrete Lyapunov equation\n\n  A'XA - E'XE + B'B = 0,\n\nwhere A and E are square real or complex matrices and B is a matrix with the same number of columns as A. The pencil A - λE must have only eigenvalues with moduli less than one.\n\nExample\n\njulia> using LinearAlgebra\n\njulia> A = [-0.5 .1;-0.1 -0.5]\n2×2 Array{Float64,2}:\n -0.5   0.1\n -0.1  -0.5\n\njulia> E = [1. 0.; 1. 1.]\n2×2 Array{Float64,2}:\n 1.0  0.0\n 1.0  1.0\n\njulia> B = [1. 1. ;1. 2.]\n2×2 Array{Float64,2}:\n 1.0  1.0\n 1.0  2.0\n\njulia> U = plyapd(A,E,B)\n2×2 UpperTriangular{Float64,Array{Float64,2}}:\n 1.56276  0.416976\n  ⋅       1.34062\n\njulia> A*U*U'*A'-E*U*U'*E'+B*B'\n2×2 Array{Float64,2}:\n 1.77636e-15  2.22045e-15\n 2.22045e-15  2.66454e-15\n\n\n\n\n\n","category":"function"},{"location":"plyapunov.html#MatrixEquations.plyapds!","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"MatrixEquations.plyapds!","text":"plyapds!(A,R;adj = false)\n\nSolve the positive discrete Lyapunov matrix equation\n\n            op(A)Xop(A)' - X + op(R)*op(R)' = 0\n\nfor X = op(U)*op(U)', where op(K) = K if adj = false and op(K) = K' if adj = true. A is a square real matrix in a real Schur form or a square complex matrix in a complex Schur form and R is an upper triangular matrix. A must have only eigenvalues with moduli less than one. R contains on output the upper triangular solution U.\n\n\n\n\n\nplyapds!(A,E,R;adj = false)\n\nSolve the generalized positive discrete Lyapunov matrix equation\n\n            op(A)Xop(A)' - op(E)Xop(E)' + op(R)*op(R)' = 0\n\nfor X = op(U)*op(U)', where op(K) = K if adj = false and op(K) = K' if adj = true. The pair (A,E) of square real or complex matrices is in a generalized Schur form and R is an upper triangular matrix. A-λE must have only eigenvalues with moduli less than one. R contains on output the upper triangular solution U.\n\n\n\n\n\n","category":"function"},{"location":"plyapunov.html#Schur-Form-Based-Solvers-1","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"Schur Form Based Solvers","text":"","category":"section"},{"location":"plyapunov.html#","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"Positive-definite Lyapunov Matrix Equation Solvers","text":"plyaps","category":"page"},{"location":"plyapunov.html#MatrixEquations.plyaps","page":"Positive-definite Lyapunov Matrix Equation Solvers","title":"MatrixEquations.plyaps","text":"U = plyaps(A, B; disc = false)\n\nCompute U, the upper triangular factor of the solution X = UU' of the continuous Lyapunov equation\n\n  AX + XA' + BB' = 0,\n\nwhere A is a square real or complex matrix in a real or complex Schur form, respectively, and B is a matrix with the same number of rows as A. A must have only eigenvalues with negative real parts. Only the upper Hessenberg part of A is referenced.\n\nU = plyaps(A', B', disc = false)\n\nCompute U, the upper triangular factor of the solution X = U'U of the continuous Lyapunov equation\n\n  A'X + XA + B'B = 0,\n\nwhere A is a square real or complex matrix in a real or complex Schur form, respectively, and B is a matrix with the same number of columns as A. A must have only eigenvalues with negative real parts. Only the upper Hessenberg part of A is referenced.\n\nU = plyaps(A, B, disc = true)\n\nCompute U, the upper triangular factor of the solution X = UU' of the discrete Lyapunov equation\n\n  AXA' - X + BB' = 0,\n\nwhere A is a square real or complex matrix in a real or complex Schur form, respectively, and B is a matrix with the same number of rows as A. A must have only eigenvalues with moduli less than one. Only the upper Hessenberg part of A is referenced.\n\nU = plyaps(A', B', disc = true)\n\nCompute U, the upper triangular factor of the solution X = U'U of the discrete Lyapunov equation\n\n  A'XA - X + B'B = 0,\n\nwhere A is a square real or complex matrix in a real or complex Schur form, respectively, and B is a matrix with the same number of columns as A. A must have only eigenvalues with moduli less than one. Only the upper Hessenberg part of A is referenced.\n\n\n\n\n\nU = plyaps(A, E, B; disc = false)\n\nCompute U, the upper triangular factor of the solution X = UU' of the generalized continuous Lyapunov equation\n\n  AXE' + EXA' + BB' = 0,\n\nwhere A and E are square real or complex matrices with the pair (A,E) in a generalied real or complex Schur form, respectively,  and B is a matrix with the same number of rows as A. The pencil A - λE must have only eigenvalues with negative real parts.\n\nU = plyaps(A', E', B', disc = false)\n\nCompute U, the upper triangular factor of the solution X = U'U of the generalized continuous Lyapunov equation\n\n  A'XE + E'XA + B'B = 0,\n\nwhere A and E are square real or complex matrices with the pair (A,E) in a generalied real or complex Schur form, respectively,  and B is a matrix with the same number of columns as A. The pencil A - λE must have only eigenvalues with negative real parts.\n\nU = plyaps(A, E, B, disc = true)\n\nCompute U, the upper triangular factor of the solution X = UU' of the generalized discrete Lyapunov equation\n\n  AXA' - EXE' + BB' = 0,\n\nwhere A and E are square real or complex matrices with the pair (A,E) in a generalied real or complex Schur form, respectively,  and B is a matrix with the same number of rows as A. The pencil A - λE must have only eigenvalues with moduli less than one.\n\nU = plyaps(A', E', B', disc = true)\n\nCompute U, the upper triangular factor of the solution X = U'U of the generalized discrete Lyapunov equation\n\n  A'XA - E'XE + B'B = 0,\n\nwhere A and E are square real or complex matrices with the pair (A,E) in a generalied real or complex Schur form, respectively,  and B is a matrix with the same number of columns as A. The pencil A - λE must have only eigenvalues with moduli less than one.\n\n\n\n\n\n","category":"function"},{"location":"sylvkr.html#Sylvester-Matrix-Equation-Solvers-using-Kronecker-product-Expansions-1","page":"Sylvester Matrix Equation Solvers using Kronecker-product Expansions","title":"Sylvester Matrix Equation Solvers using Kronecker-product Expansions","text":"","category":"section"},{"location":"sylvkr.html#","page":"Sylvester Matrix Equation Solvers using Kronecker-product Expansions","title":"Sylvester Matrix Equation Solvers using Kronecker-product Expansions","text":"sylvckr\nsylvdkr\ngsylvkr\nsylvsyskr\ndsylvsyskr","category":"page"},{"location":"sylvkr.html#MatrixEquations.sylvckr","page":"Sylvester Matrix Equation Solvers using Kronecker-product Expansions","title":"MatrixEquations.sylvckr","text":"X = sylvckr(A,B,C)\n\nSolve the continuous Sylvester matrix equation\n\n            AX + XB = C\n\nusing the Kronecker product expansion of equations. A and B are square matrices, and A and -B must not have common eigenvalues. This function is not recommended for large order matrices.\n\n\n\n\n\n","category":"function"},{"location":"sylvkr.html#MatrixEquations.sylvdkr","page":"Sylvester Matrix Equation Solvers using Kronecker-product Expansions","title":"MatrixEquations.sylvdkr","text":"X = sylvdkr(A,B,C)\n\nSolve the discrete Sylvester matrix equation\n\n            AXB + X = C\n\nusing the Kronecker product expansion of equations. A and B are square matrices, and A and -B must not have common reciprocal eigenvalues. This function is not recommended for large order matrices.\n\n\n\n\n\n","category":"function"},{"location":"sylvkr.html#MatrixEquations.gsylvkr","page":"Sylvester Matrix Equation Solvers using Kronecker-product Expansions","title":"MatrixEquations.gsylvkr","text":"X = gsylvkr(A,B,C,D,E)\n\nSolve the generalized Sylvester matrix equation\n\n            AXB + CXD = E\n\nusing the Kronecker product expansion of equations. A, B, C and D are square matrices. The pencils A-λC and D+λB must be regular and must not have common eigenvalues. This function is not recommended for large order matrices.\n\n\n\n\n\n","category":"function"},{"location":"sylvkr.html#MatrixEquations.sylvsyskr","page":"Sylvester Matrix Equation Solvers using Kronecker-product Expansions","title":"MatrixEquations.sylvsyskr","text":"sylvsyskr(A,B,C,D,E,F) -> (X,Y)\n\nSolve the Sylvester system of matrix equations\n\n            AX + YB = C\n            DX + YE = F\n\nusing the Kronecker product expansion of equations. (A,D), (B,E) are pairs of square matrices of the same size. The pencils A-λD and -B+λE must be regular and must not have common eigenvalues. This function is not recommended for large order matrices.\n\n\n\n\n\n","category":"function"},{"location":"sylvkr.html#MatrixEquations.dsylvsyskr","page":"Sylvester Matrix Equation Solvers using Kronecker-product Expansions","title":"MatrixEquations.dsylvsyskr","text":"dsylvsyskr(A,B,C,D,E,F) -> (X,Y)\n\nSolve the dual Sylvester system of matrix equations\n\n   AX + DY = C\n   XB + YE = F\n\nusing the Kronecker product expansion of equations. (A,D), (B,E) are pairs of square matrices of the same size. The pencils A-λD and -B+λE must be regular and must not have common eigenvalues. This function is not recommended for large order matrices.\n\n\n\n\n\n","category":"function"},{"location":"index.html#","page":"Home","title":"Home","text":"CurrentModule = MatrixEquations\nDocTestSetup = quote\n    using MatrixEquations\nend","category":"page"},{"location":"index.html#MatrixEquations.jl-1","page":"Home","title":"MatrixEquations.jl","text":"","category":"section"},{"location":"index.html#","page":"Home","title":"Home","text":"(Image: DocBuild) (Image: Code on Github.)","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"This collection of Julia functions is an attemp to implement high performance numerical software to solve classes of Lyapunov, Sylvester and Riccati matrix equations at a performance level comparable with efficient structure exploiting Fortran implementations, as those available in the Systems and Control Library SLICOT. This goal has been fully achieved for Lyapunov and Sylvester equation solvers, for which the codes for both real and complex data perform at practically same performance level as similar functions available in the MATLAB Control System Toolbox (which rely on SLICOT).","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"The available functions in the MatrixEquations.jl package cover both standard and generalized continuous and discrete Lyapunov, Sylvester and Riccati equations for both real and complex data. The functions for the solution of Lyapunov and Sylvester equations rely on efficient structure exploiting solvers for which the input data are in Schur or generalized Schur forms. A comprehensive set of Lyapunov and Sylvester operators has been implemented, which allow the estimation of condition numbers of these operators. The implementation of Riccati equation solvers employ orthogonal Schur vectors based methods and their extensions to linear matrix pencil based reduction approaches. The calls of all functions with adjoint (in complex case) or transposed (in real case) arguments are fully supported by appropriate computational algorithms, thus the matrix copying operations are mostly avoided.","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"The current version of the package includes the following functions:","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"Solution of Lyapunov equations","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"Function Description\nlyapc Solution of the continuous Lyapunov equations\nlyapd Solution of the discrete Lyapunov equations\nplyapc Solution of the positive continuous Lyapunov equations\nplyapd Solution of the positive discrete Lyapunov equations","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"Solution of algebraic  Riccati equations","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"Function Description\narec Solution of the continuous Riccati equations\ngarec Solution of the generalized continuous Riccati equation\nared Solution of the discrete Riccati equation\ngared Solution of the generalized discrete Riccati equation","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"Solution of Sylvester equations and systems","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"Function Description\nsylvc Solution of the (continuous) Sylvester equations\nsylvd Solution of the (discrete) Sylvester equations\ngsylv Solution of the generalized Sylvester equations\nsylvsys Solution of the Sylvester system of matrix equations\ndsylvsys Solution of the dual Sylvester system of matrix equations","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"Norm, condition and separation estimation of linear operators","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"Function Description\nopnorm1 Computation of the 1-norm of a linear operator\nopnorm1est Estimation of the 1-norm of a linear operator\noprcondest Estimation of the reciprocal 1-norm condition number of an operator\nopsepest Estimation of the separation of a linear operator","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"The general solvers of Lyapunov and Sylvester equations rely on a set of specialized solvers for real or complex matrices in appropriate Schur forms. For testing purposes, a set of solvers for Sylvester equations has been implemented, which employ the Kronecker-product expansion of the equations. These solvers are not recommended for large order matrices. The norms, reciprocal condition numbers and separations can be estimated for a comprehensive set of predefined Lyapunov and Sylvester operators. A complete list of implemented functions is available here.","category":"page"},{"location":"index.html#Future-plans-1","page":"Home","title":"Future plans","text":"","category":"section"},{"location":"index.html#","page":"Home","title":"Home","text":"The collection of tools can be extended by adding new functionality, such as expert solvers, which additionally compute error bounds and condition estimates, or solvers for new classes of Riccati equations, as those arising in game-theoretic optimization problems. Further performance improvements are still possible by employing blocking based variants of solvers for Lyapunov and Sylvester equations.","category":"page"},{"location":"index.html#[Release-Notes](https://github.com/andreasvarga/MatrixEquations.jl/blob/master/ReleaseNotes.md)-1","page":"Home","title":"Release Notes","text":"","category":"section"},{"location":"index.html#Main-developer-1","page":"Home","title":"Main developer","text":"","category":"section"},{"location":"index.html#","page":"Home","title":"Home","text":"Andreas Varga","category":"page"},{"location":"index.html#","page":"Home","title":"Home","text":"License: MIT (expat)","category":"page"},{"location":"condest.html#Norm,-Condition-Number-and-Separation-Estimations-1","page":"Norm, Condition Number and Separation Estimations","title":"Norm, Condition Number and Separation Estimations","text":"","category":"section"},{"location":"condest.html#","page":"Norm, Condition Number and Separation Estimations","title":"Norm, Condition Number and Separation Estimations","text":"opnorm1\nopnorm1est\noprcondest\nopsepest","category":"page"},{"location":"condest.html#MatrixEquations.opnorm1","page":"Norm, Condition Number and Separation Estimations","title":"MatrixEquations.opnorm1","text":"γ = opnorm1(op)\n\nCompute γ, the induced 1-norm of the linear operator op, as the maximum of 1-norm of the columns of the associated m x n matrix M = Matrix(op):\n\ngamma = op_1 = max_1  j  n M_j_1\n\nwith M_j the j-th column of M. This function is not recommended to be used for large order operators.\n\nExamples\n\njulia> A = [-6. -2. 1.; 5. 1. -1; -4. -2. -1.]\n3×3 Array{Float64,2}:\n -6.0  -2.0   1.0\n  5.0   1.0  -1.0\n -4.0  -2.0  -1.0\n\njulia> opnorm1(lyapop(A))\n30.0\n\njulia> opnorm1(invlyapop(A))\n3.7666666666666706\n\n\n\n\n\n","category":"function"},{"location":"condest.html#MatrixEquations.opnorm1est","page":"Norm, Condition Number and Separation Estimations","title":"MatrixEquations.opnorm1est","text":"γ = opnorm1est(op)\n\nCompute γ, a lower bound of the 1-norm of the square linear operator op, using reverse communication based computations to evaluate op * x and op' * x. It is expected that in most cases gamma  op_110, which is usually acceptable for estimating the condition numbers of linear operators.\n\nExamples\n\njulia> A = [-6. -2. 1.; 5. 1. -1; -4. -2. -1.]\n3×3 Array{Float64,2}:\n -6.0  -2.0   1.0\n  5.0   1.0  -1.0\n -4.0  -2.0  -1.0\n\njulia> opnorm1est(lyapop(A))\n18.0\n\njulia> opnorm1est(invlyapop(A))\n3.76666666666667\n\n\n\n\n\n","category":"function"},{"location":"condest.html#MatrixEquations.oprcondest","page":"Norm, Condition Number and Separation Estimations","title":"MatrixEquations.oprcondest","text":"rcond = oprcondest(op, opinv; exact = false)\n\nCompute rcond, an estimation of the 1-norm reciprocal condition number of a linear operator op, where opinv is the inverse operator inv(op). The estimate is computed as textrcond = 1  (op_1opinv_1), using estimates of the 1-norm, if exact = false, or computed exact values of the 1-norm, if exact = true. The exact = true option is not recommended for large order operators.\n\nNote: No check is performed to verify that opinv = inv(op).\n\nExamples\n\njulia> A = [-6. -2. 1.; 5. 1. -1; -4. -2. -1.]\n3×3 Array{Float64,2}:\n -6.0  -2.0   1.0\n  5.0   1.0  -1.0\n -4.0  -2.0  -1.0\n\njulia> oprcondest(lyapop(A),invlyapop(A))\n0.014749262536873142\n \njulia> 1/opnorm1est(lyapop(A))/opnorm1est(invlyapop(A))\n0.014749262536873142\n \njulia> oprcondest(lyapop(A),invlyapop(A),exact = true)\n0.008849557522123885\n \njulia> 1/opnorm1(lyapop(A))/opnorm1(invlyapop(A))\n0.008849557522123885 \n\n\n\n\n\n","category":"function"},{"location":"condest.html#MatrixEquations.opsepest","page":"Norm, Condition Number and Separation Estimations","title":"MatrixEquations.opsepest","text":"sep = opsepest(opinv; exact = false)\n\nCompute sep, an estimation of the 1-norm separation of a linear operator op, where opinv is the inverse operator inv(op). The estimate is computed as textsep  = 1  opinv_1 , using an estimate of the 1-norm, if exact = false, or the computed exact value of the 1-norm, if exact = true. The exact = true option is not recommended for large order operators.\n\nThe separation of the operator op is defined as\n\ntextsep = displaystylemin_Xneq 0 fracop*XX\n\nAn estimate of the reciprocal condition number of op can be computed as textsepop_1.\n\nExample\n\njulia> A = [-6. -2. 1.; 5. 1. -1; -4. -2. -1.]\n3×3 Array{Float64,2}:\n -6.0  -2.0   1.0\n  5.0   1.0  -1.0\n -4.0  -2.0  -1.0\n\njulia> opsepest(invlyapop(A))\n0.26548672566371656\n\njulia> 1/opnorm1est(invlyapop(A))\n0.26548672566371656\n\njulia> opsepest(invlyapop(A),exact = true)\n0.26548672566371656\n\njulia> 1/opnorm1(invlyapop(A))\n0.26548672566371656\n\n\n\n\n\n","category":"function"}]
}
